<!-- Title: agentscope.model._gemini_model - AgentScope -->
<!-- URL: https://doc.agentscope.io/zh_CN/_modules/agentscope/model/_gemini_model.html -->

          <h1>agentscope.model._gemini_model 源代码</h1><div class="highlight"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1"># mypy: disable-error-code="dict-item"</span>
<span class="sd">"""The Google Gemini model in agentscope."""</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AsyncGenerator</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">AsyncIterator</span><span class="p">,</span>
    <span class="n">Literal</span><span class="p">,</span>
    <span class="n">Type</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.._logging</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.._utils._common</span><span class="w"> </span><span class="kn">import</span> <span class="n">_json_loads_with_repair</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..message</span><span class="w"> </span><span class="kn">import</span> <span class="n">ToolUseBlock</span><span class="p">,</span> <span class="n">TextBlock</span><span class="p">,</span> <span class="n">ThinkingBlock</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._model_usage</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatUsage</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._model_base</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatModelBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">._model_response</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatResponse</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..tracing</span><span class="w"> </span><span class="kn">import</span> <span class="n">trace_llm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..types</span><span class="w"> </span><span class="kn">import</span> <span class="n">JSONSerializableObject</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">google.genai.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">GenerateContentResponse</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">GenerateContentResponse</span> <span class="o">=</span> <span class="s2">"google.genai.types.GenerateContentResponse"</span>


<div class="viewcode-block" id="GeminiChatModel">
<a class="viewcode-back" href="../../../api/agentscope.model.html#agentscope.model.GeminiChatModel">[文档]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">GeminiChatModel</span><span class="p">(</span><span class="n">ChatModelBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""The Google Gemini chat model class in agentscope."""</span>

<div class="viewcode-block" id="GeminiChatModel.__init__">
<a class="viewcode-back" href="../../../api/agentscope.model.html#agentscope.model.GeminiChatModel.__init__">[文档]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">stream</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">thinking_config</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">client_args</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">generate_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">JSONSerializableObject</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Initialize the Gemini chat model.</span>

<span class="sd">        Args:</span>
<span class="sd">            model_name (`str`):</span>
<span class="sd">                The name of the Gemini model to use, e.g. "gemini-2.5-flash".</span>
<span class="sd">            api_key (`str`):</span>
<span class="sd">                The API key for Google Gemini.</span>
<span class="sd">            stream (`bool`, default `True`):</span>
<span class="sd">                Whether to use streaming output or not.</span>
<span class="sd">            thinking_config (`dict | None`, optional):</span>
<span class="sd">                Thinking config, supported models are 2.5 Pro, 2.5 Flash, etc.</span>
<span class="sd">                Refer to https://ai.google.dev/gemini-api/docs/thinking for</span>
<span class="sd">                more details.</span>

<span class="sd">                .. code-block:: python</span>
<span class="sd">                    :caption: Example of thinking_config</span>

<span class="sd">                    {</span>
<span class="sd">                        "include_thoughts": True, # enable thoughts or not</span>
<span class="sd">                        "thinking_budget": 1024   # Max tokens for reasoning</span>
<span class="sd">                    }</span>

<span class="sd">            client_args (`dict`, default `None`):</span>
<span class="sd">                The extra keyword arguments to initialize the OpenAI client.</span>
<span class="sd">            generate_kwargs (`dict[str, JSONSerializableObject] | None`, \</span>
<span class="sd">             optional):</span>
<span class="sd">               The extra keyword arguments used in Gemini API generation,</span>
<span class="sd">               e.g. `temperature`, `seed`.</span>
<span class="sd">        """</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">google</span><span class="w"> </span><span class="kn">import</span> <span class="n">genai</span>
        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">"Please install gemini Python sdk with "</span>
                <span class="s2">"`pip install -q -U google-genai`"</span><span class="p">,</span>
            <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">stream</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">genai</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span>
            <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
            <span class="o">**</span><span class="p">(</span><span class="n">client_args</span> <span class="ow">or</span> <span class="p">{}),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">thinking_config</span> <span class="o">=</span> <span class="n">thinking_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span> <span class="o">=</span> <span class="n">generate_kwargs</span> <span class="ow">or</span> <span class="p">{}</span></div>


<div class="viewcode-block" id="GeminiChatModel.__call__">
<a class="viewcode-back" href="../../../api/agentscope.model.html#agentscope.model.GeminiChatModel.__call__">[文档]</a>
    <span class="nd">@trace_llm</span>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
        <span class="n">tools</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tool_choice</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">"auto"</span><span class="p">,</span> <span class="s2">"none"</span><span class="p">,</span> <span class="s2">"any"</span><span class="p">,</span> <span class="s2">"required"</span><span class="p">]</span>
        <span class="o">|</span> <span class="nb">str</span>
        <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">structured_model</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">BaseModel</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">config_kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ChatResponse</span> <span class="o">|</span> <span class="n">AsyncGenerator</span><span class="p">[</span><span class="n">ChatResponse</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Call the Gemini model with the provided arguments.</span>

<span class="sd">        Args:</span>
<span class="sd">            messages (`list[dict[str, Any]]`):</span>
<span class="sd">                A list of dictionaries, where `role` and `content` fields are</span>
<span class="sd">                required.</span>
<span class="sd">            tools (`list[dict] | None`, default `None`):</span>
<span class="sd">                The tools JSON schemas that the model can use.</span>
<span class="sd">            tool_choice (`Literal["auto", "none", "any", "required"] | str \</span>
<span class="sd">            | None`, default `None`):</span>
<span class="sd">                Controls which (if any) tool is called by the model.</span>
<span class="sd">                 Can be "auto", "none", "any", "required", or specific tool</span>
<span class="sd">                 name. For more details, please refer to</span>
<span class="sd">                 https://ai.google.dev/gemini-api/docs/function-calling?hl=en&amp;example=meeting#function_calling_modes</span>
<span class="sd">            structured_model (`Type[BaseModel] | None`, default `None`):</span>
<span class="sd">                A Pydantic BaseModel class that defines the expected structure</span>
<span class="sd">                for the model's output.</span>

<span class="sd">                .. note:: When `structured_model` is specified,</span>
<span class="sd">                    both `tools` and `tool_choice` parameters are ignored,</span>
<span class="sd">                    and the model will only perform structured output</span>
<span class="sd">                    generation without calling any other tools.</span>

<span class="sd">                For more details, please refer to</span>
<span class="sd">                    https://ai.google.dev/gemini-api/docs/structured-output</span>

<span class="sd">            **config_kwargs (`Any`):</span>
<span class="sd">                The keyword arguments for Gemini chat completions API.</span>
<span class="sd">        """</span>

        <span class="n">config</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"thinking_config"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">thinking_config</span><span class="p">,</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_kwargs</span><span class="p">,</span>
            <span class="o">**</span><span class="n">config_kwargs</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">tools</span><span class="p">:</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">"tools"</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_tools_json_schemas</span><span class="p">(</span><span class="n">tools</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">tool_choice</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_tool_choice</span><span class="p">(</span><span class="n">tool_choice</span><span class="p">,</span> <span class="n">tools</span><span class="p">)</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">"tool_config"</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_tool_choice</span><span class="p">(</span><span class="n">tool_choice</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">structured_model</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tools</span> <span class="ow">or</span> <span class="n">tool_choice</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">"structured_model is provided. Both 'tools' and "</span>
                    <span class="s2">"'tool_choice' parameters will be overridden and "</span>
                    <span class="s2">"ignored. The model will only perform structured output "</span>
                    <span class="s2">"generation without calling any other tools."</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"tools"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"tool_config"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">"response_mime_type"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"application/json"</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">"response_schema"</span><span class="p">]</span> <span class="o">=</span> <span class="n">structured_model</span>

        <span class="c1"># Prepare the arguments for the Gemini API call</span>
        <span class="n">kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">JSONSerializableObject</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"model"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
            <span class="s2">"contents"</span><span class="p">:</span> <span class="n">messages</span><span class="p">,</span>
            <span class="s2">"config"</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">start_datetime</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stream</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">aio</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">generate_content_stream</span><span class="p">(</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_gemini_stream_generation_response</span><span class="p">(</span>
                <span class="n">start_datetime</span><span class="p">,</span>
                <span class="n">response</span><span class="p">,</span>
                <span class="n">structured_model</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># non-streaming</span>
        <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">aio</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">generate_content</span><span class="p">(</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">parsed_response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_gemini_generation_response</span><span class="p">(</span>
            <span class="n">start_datetime</span><span class="p">,</span>
            <span class="n">response</span><span class="p">,</span>
            <span class="n">structured_model</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">parsed_response</span></div>


    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_parse_gemini_stream_generation_response</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">start_datetime</span><span class="p">:</span> <span class="n">datetime</span><span class="p">,</span>
        <span class="n">response</span><span class="p">:</span> <span class="n">AsyncIterator</span><span class="p">[</span><span class="n">GenerateContentResponse</span><span class="p">],</span>
        <span class="n">structured_model</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">BaseModel</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncGenerator</span><span class="p">[</span><span class="n">ChatResponse</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">"""Given a Gemini streaming generation response, extract the</span>
<span class="sd">        content blocks and usages from it and yield ChatResponse objects.</span>

<span class="sd">        Args:</span>
<span class="sd">            start_datetime (`datetime`):</span>
<span class="sd">                The start datetime of the response generation.</span>
<span class="sd">            response (`AsyncIterator[GenerateContentResponse]`):</span>
<span class="sd">                Gemini GenerateContentResponse async iterator to parse.</span>
<span class="sd">            structured_model (`Type[BaseModel] | None`, default `None`):</span>
<span class="sd">                A Pydantic BaseModel class that defines the expected structure</span>
<span class="sd">                for the model's output.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `AsyncGenerator[ChatResponse, None]`:</span>
<span class="sd">                An async generator that yields ChatResponse objects containing</span>
<span class="sd">                the content blocks and usage information for each chunk in the</span>
<span class="sd">                streaming response.</span>

<span class="sd">        .. note::</span>
<span class="sd">            If `structured_model` is not `None`, the expected structured output</span>
<span class="sd">            will be stored in the metadata of the `ChatResponse`.</span>
<span class="sd">        """</span>

        <span class="n">text</span> <span class="o">=</span> <span class="s2">""</span>
        <span class="n">thinking</span> <span class="o">=</span> <span class="s2">""</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">response</span><span class="p">:</span>
            <span class="n">content_block</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># Thinking parts</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">chunk</span><span class="o">.</span><span class="n">candidates</span>
                <span class="ow">and</span> <span class="n">chunk</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>
                <span class="ow">and</span> <span class="n">chunk</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">parts</span>
            <span class="p">):</span>
                <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">chunk</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">parts</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">part</span><span class="o">.</span><span class="n">thought</span> <span class="ow">and</span> <span class="n">part</span><span class="o">.</span><span class="n">text</span><span class="p">:</span>
                        <span class="n">thinking</span> <span class="o">+=</span> <span class="n">part</span><span class="o">.</span><span class="n">text</span>

            <span class="c1"># Text parts</span>
            <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">text</span><span class="p">:</span>
                <span class="n">text</span> <span class="o">+=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">text</span>
                <span class="k">if</span> <span class="n">structured_model</span><span class="p">:</span>
                    <span class="n">metadata</span> <span class="o">=</span> <span class="n">_json_loads_with_repair</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

            <span class="c1"># Function calls</span>
            <span class="n">tool_calls</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">function_calls</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">function_call</span> <span class="ow">in</span> <span class="n">chunk</span><span class="o">.</span><span class="n">function_calls</span><span class="p">:</span>
                    <span class="n">tool_calls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">ToolUseBlock</span><span class="p">(</span>
                            <span class="nb">type</span><span class="o">=</span><span class="s2">"tool_use"</span><span class="p">,</span>
                            <span class="nb">id</span><span class="o">=</span><span class="n">function_call</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                            <span class="n">name</span><span class="o">=</span><span class="n">function_call</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                            <span class="nb">input</span><span class="o">=</span><span class="n">function_call</span><span class="o">.</span><span class="n">args</span> <span class="ow">or</span> <span class="p">{},</span>
                        <span class="p">),</span>
                    <span class="p">)</span>

            <span class="n">usage</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">usage_metadata</span><span class="p">:</span>
                <span class="n">usage</span> <span class="o">=</span> <span class="n">ChatUsage</span><span class="p">(</span>
                    <span class="n">input_tokens</span><span class="o">=</span><span class="n">chunk</span><span class="o">.</span><span class="n">usage_metadata</span><span class="o">.</span><span class="n">prompt_token_count</span><span class="p">,</span>
                    <span class="n">output_tokens</span><span class="o">=</span><span class="n">chunk</span><span class="o">.</span><span class="n">usage_metadata</span><span class="o">.</span><span class="n">total_token_count</span>
                    <span class="o">-</span> <span class="n">chunk</span><span class="o">.</span><span class="n">usage_metadata</span><span class="o">.</span><span class="n">prompt_token_count</span><span class="p">,</span>
                    <span class="n">time</span><span class="o">=</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_datetime</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">(),</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">thinking</span><span class="p">:</span>
                <span class="n">content_block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">ThinkingBlock</span><span class="p">(</span>
                        <span class="nb">type</span><span class="o">=</span><span class="s2">"thinking"</span><span class="p">,</span>
                        <span class="n">thinking</span><span class="o">=</span><span class="n">thinking</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">text</span><span class="p">:</span>
                <span class="n">content_block</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">TextBlock</span><span class="p">(</span>
                        <span class="nb">type</span><span class="o">=</span><span class="s2">"text"</span><span class="p">,</span>
                        <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>

            <span class="n">content_block</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="o">*</span><span class="n">tool_calls</span><span class="p">,</span>
                <span class="p">],</span>
            <span class="p">)</span>

            <span class="n">parsed_chunk</span> <span class="o">=</span> <span class="n">ChatResponse</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="n">content_block</span><span class="p">,</span>
                <span class="n">usage</span><span class="o">=</span><span class="n">usage</span><span class="p">,</span>
                <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">yield</span> <span class="n">parsed_chunk</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_parse_gemini_generation_response</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">start_datetime</span><span class="p">:</span> <span class="n">datetime</span><span class="p">,</span>
        <span class="n">response</span><span class="p">:</span> <span class="n">GenerateContentResponse</span><span class="p">,</span>
        <span class="n">structured_model</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">BaseModel</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ChatResponse</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Given a Gemini chat completion response object, extract the content</span>
<span class="sd">           blocks and usages from it.</span>

<span class="sd">        Args:</span>
<span class="sd">            start_datetime (`datetime`):</span>
<span class="sd">                The start datetime of the response generation.</span>
<span class="sd">            response (`ChatCompletion`):</span>
<span class="sd">                The OpenAI chat completion response object to parse.</span>
<span class="sd">            structured_model (`Type[BaseModel] | None`, default `None`):</span>
<span class="sd">                A Pydantic BaseModel class that defines the expected structure</span>
<span class="sd">                for the model's output.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ChatResponse (`ChatResponse`):</span>
<span class="sd">                A ChatResponse object containing the content blocks and usage.</span>

<span class="sd">        .. note::</span>
<span class="sd">            If `structured_model` is not `None`, the expected structured output</span>
<span class="sd">            will be stored in the metadata of the `ChatResponse`.</span>
<span class="sd">        """</span>
        <span class="n">content_blocks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TextBlock</span> <span class="o">|</span> <span class="n">ToolUseBlock</span> <span class="o">|</span> <span class="n">ThinkingBlock</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">metadata</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">response</span><span class="o">.</span><span class="n">candidates</span>
            <span class="ow">and</span> <span class="n">response</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span>
            <span class="ow">and</span> <span class="n">response</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">parts</span>
        <span class="p">):</span>
            <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">parts</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">part</span><span class="o">.</span><span class="n">thought</span> <span class="ow">and</span> <span class="n">part</span><span class="o">.</span><span class="n">text</span><span class="p">:</span>
                    <span class="n">content_blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="n">ThinkingBlock</span><span class="p">(</span>
                            <span class="nb">type</span><span class="o">=</span><span class="s2">"thinking"</span><span class="p">,</span>
                            <span class="n">thinking</span><span class="o">=</span><span class="n">part</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                        <span class="p">),</span>
                    <span class="p">)</span>

        <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">:</span>
            <span class="n">content_blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">TextBlock</span><span class="p">(</span>
                    <span class="nb">type</span><span class="o">=</span><span class="s2">"text"</span><span class="p">,</span>
                    <span class="n">text</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">structured_model</span><span class="p">:</span>
                <span class="n">metadata</span> <span class="o">=</span> <span class="n">_json_loads_with_repair</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">function_calls</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">tool_call</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">function_calls</span><span class="p">:</span>
                <span class="n">content_blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">ToolUseBlock</span><span class="p">(</span>
                        <span class="nb">type</span><span class="o">=</span><span class="s2">"tool_use"</span><span class="p">,</span>
                        <span class="nb">id</span><span class="o">=</span><span class="n">tool_call</span><span class="o">.</span><span class="n">id</span><span class="p">,</span>
                        <span class="n">name</span><span class="o">=</span><span class="n">tool_call</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                        <span class="nb">input</span><span class="o">=</span><span class="n">tool_call</span><span class="o">.</span><span class="n">args</span> <span class="ow">or</span> <span class="p">{},</span>
                    <span class="p">),</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">usage_metadata</span><span class="p">:</span>
            <span class="n">usage</span> <span class="o">=</span> <span class="n">ChatUsage</span><span class="p">(</span>
                <span class="n">input_tokens</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">usage_metadata</span><span class="o">.</span><span class="n">prompt_token_count</span><span class="p">,</span>
                <span class="n">output_tokens</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">usage_metadata</span><span class="o">.</span><span class="n">total_token_count</span>
                <span class="o">-</span> <span class="n">response</span><span class="o">.</span><span class="n">usage_metadata</span><span class="o">.</span><span class="n">prompt_token_count</span><span class="p">,</span>
                <span class="n">time</span><span class="o">=</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_datetime</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">(),</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">usage</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="n">ChatResponse</span><span class="p">(</span>
            <span class="n">content</span><span class="o">=</span><span class="n">content_blocks</span><span class="p">,</span>
            <span class="n">usage</span><span class="o">=</span><span class="n">usage</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_format_tools_json_schemas</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">schemas</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">"""Format the tools JSON schema into required format for Gemini API.</span>

<span class="sd">        Args:</span>
<span class="sd">            schemas (`dict[str, Any]`):</span>
<span class="sd">                The tools JSON schemas.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Dict[str, Any]]:</span>
<span class="sd">                A list containing a dictionary with the</span>
<span class="sd">                "function_declarations" key, which maps to a list of</span>
<span class="sd">                function definitions.</span>

<span class="sd">        Example:</span>
<span class="sd">            .. code-block:: python</span>
<span class="sd">                :caption: Example tool schemas of Gemini API</span>

<span class="sd">                # Input JSON schema</span>
<span class="sd">                schemas = [</span>
<span class="sd">                    {</span>
<span class="sd">                        'type': 'function',</span>
<span class="sd">                        'function': {</span>
<span class="sd">                            'name': 'execute_shell_command',</span>
<span class="sd">                            'description': 'xxx',</span>
<span class="sd">                            'parameters': {</span>
<span class="sd">                                'type': 'object',</span>
<span class="sd">                                'properties': {</span>
<span class="sd">                                    'command': {</span>
<span class="sd">                                        'type': 'string',</span>
<span class="sd">                                        'description': 'xxx.'</span>
<span class="sd">                                    },</span>
<span class="sd">                                    'timeout': {</span>
<span class="sd">                                        'type': 'integer',</span>
<span class="sd">                                        'default': 300</span>
<span class="sd">                                    }</span>
<span class="sd">                                },</span>
<span class="sd">                                'required': ['command']</span>
<span class="sd">                            }</span>
<span class="sd">                        }</span>
<span class="sd">                    }</span>
<span class="sd">                ]</span>

<span class="sd">                # Output format (Gemini API expected):</span>
<span class="sd">                [</span>
<span class="sd">                    {</span>
<span class="sd">                        'function_declarations': [</span>
<span class="sd">                            {</span>
<span class="sd">                                'name': 'execute_shell_command',</span>
<span class="sd">                                'description': 'xxx.',</span>
<span class="sd">                                'parameters': {</span>
<span class="sd">                                    'type': 'object',</span>
<span class="sd">                                    'properties': {</span>
<span class="sd">                                        'command': {</span>
<span class="sd">                                            'type': 'string',</span>
<span class="sd">                                            'description': 'xxx.'</span>
<span class="sd">                                        },</span>
<span class="sd">                                        'timeout': {</span>
<span class="sd">                                            'type': 'integer',</span>
<span class="sd">                                            'default': 300</span>
<span class="sd">                                        }</span>
<span class="sd">                                    },</span>
<span class="sd">                                    'required': ['command']</span>
<span class="sd">                                }</span>
<span class="sd">                            }</span>
<span class="sd">                        ]</span>
<span class="sd">                    }</span>
<span class="sd">                ]</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">"function_declarations"</span><span class="p">:</span> <span class="p">[</span>
                    <span class="n">_</span><span class="p">[</span><span class="s2">"function"</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">schemas</span> <span class="k">if</span> <span class="s2">"function"</span> <span class="ow">in</span> <span class="n">_</span>
                <span class="p">],</span>
            <span class="p">},</span>
        <span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_format_tool_choice</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tool_choice</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">"auto"</span><span class="p">,</span> <span class="s2">"none"</span><span class="p">,</span> <span class="s2">"any"</span><span class="p">,</span> <span class="s2">"required"</span><span class="p">]</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">"""Format tool_choice parameter for API compatibility.</span>

<span class="sd">        Args:</span>
<span class="sd">            tool_choice (`Literal["auto", "none"] | str | None`, default \</span>
<span class="sd">            `None`):</span>
<span class="sd">                Controls which (if any) tool is called by the model.</span>
<span class="sd">                 Can be "auto", "none", "any", "required", or specific tool</span>
<span class="sd">                 name.</span>
<span class="sd">                 For more details, please refer to</span>
<span class="sd">                 https://ai.google.dev/gemini-api/docs/function-calling?hl=en&amp;example=meeting#function_calling_modes</span>
<span class="sd">        Returns:</span>
<span class="sd">            `dict | None`:</span>
<span class="sd">                The formatted tool choice configuration dict, or None if</span>
<span class="sd">                    tool_choice is None.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="n">tool_choice</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="n">mode_mapping</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"auto"</span><span class="p">:</span> <span class="s2">"AUTO"</span><span class="p">,</span>
            <span class="s2">"none"</span><span class="p">:</span> <span class="s2">"NONE"</span><span class="p">,</span>
            <span class="s2">"any"</span><span class="p">:</span> <span class="s2">"ANY"</span><span class="p">,</span>
            <span class="s2">"required"</span><span class="p">:</span> <span class="s2">"ANY"</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="n">mode_mapping</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">tool_choice</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mode</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">"function_calling_config"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"mode"</span><span class="p">:</span> <span class="n">mode</span><span class="p">}}</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">"function_calling_config"</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">"mode"</span><span class="p">:</span> <span class="s2">"ANY"</span><span class="p">,</span>
                <span class="s2">"allowed_function_names"</span><span class="p">:</span> <span class="p">[</span><span class="n">tool_choice</span><span class="p">],</span>
            <span class="p">},</span>
        <span class="p">}</span></div>

</pre></div>
        